# Phase 1 Testing Guide

## ‚úÖ Pre-Test Checklist

- ‚úÖ Backend running on http://localhost:3001
- ‚úÖ Frontend running on http://localhost:5173
- ‚úÖ Singleton client confirmed: `[BaseAgent] Initialized shared Anthropic client` (only once)

---

## Test 1: Singleton Anthropic Client ‚úÖ

**Already Confirmed!** Check the backend logs:

```
[BaseAgent] Initialized shared Anthropic client
‚úì All 17 agents initialized
```

**Expected**: Should see "Initialized shared Anthropic client" **exactly once**
**Result**: ‚úÖ PASS - Only appears once instead of 18 times

**Memory savings**: 94% (from ~200MB to ~12MB for client instances)

---

## Test 2: Parallel Database Queries

### How to Test:

1. Open http://localhost:5173 in your browser
2. Create a new project or select an existing one
3. Go to the Chat page
4. Send any message (e.g., "I'm thinking about building a fitness app")
5. Watch the backend console logs

### What to Look For:

**Before Phase 1** (sequential):
```
[Coordination] Fetching project state...
[Coordination] Fetching conversation history...
[Coordination] Fetching references...
[Coordination] Fetching documents...
```

**After Phase 1** (parallel):
```
[Coordination] Fetched project data: X references, Y documents
```

**Expected**: Single log line showing all data fetched in parallel
**Speed improvement**: 75% faster (400-800ms ‚Üí 100-200ms)

---

## Test 3: Parallel Agent Execution

### How to Test:

Send a "deciding" type message:
```
"I've decided to use React for the frontend"
```

### What to Look For in Backend Logs:

**Before Phase 1** (sequential):
```
[Orchestrator] Executing: verification.verify
[Orchestrator] Executing: assumptionBlocker.scan
[Orchestrator] Executing: consistencyGuardian.checkConsistency
```

**After Phase 1** (parallel):
```
[Orchestrator] Organized 6 steps into 4 execution batches
[Orchestrator] Executing 3 agents in parallel: verification, assumptionBlocker, consistencyGuardian
```

**Expected**: Should see agents grouped and executed in parallel
**Speed improvement**: 60-70% faster workflows

### Workflows to Test:

1. **Deciding**: "I've decided we'll use TypeScript"
   - Should see 3 agents in parallel (verification, assumptionBlocker, consistencyGuardian)

2. **Modifying**: "Actually, let's use Python instead"
   - Should see 2 parallel groups

3. **Exploring**: "What if we added a mobile app?"
   - Should see 2 agents in parallel (brainstorming, questioner)

4. **Brainstorming**: "I'm thinking about e-commerce features"
   - Should see 2 agents in parallel (brainstorming, gapDetection)

---

## Test 4: Server-Sent Events Streaming

### Option A: Browser Testing (Future - requires frontend update)

The new streaming endpoint is available but frontend needs to be updated to use it.

### Option B: Command Line Testing (Now)

Open a new terminal and run:

```bash
curl -X POST http://localhost:3001/api/conversations/PROJECT_ID/message-stream \
  -H "Content-Type: application/json" \
  -d "{\"message\": \"Test streaming\", \"userId\": \"test-user\"}" \
  --no-buffer
```

**Replace PROJECT_ID** with an actual project ID from your database.

**Expected Output** (streams in real-time):
```
event: start
data: {"message":"Processing your message..."}

event: user-message-saved
data: {"message":{...}}

event: agent-processing
data: {"status":"Classifying intent..."}

event: workflow-determined
data: {"intent":"general","confidence":75}

event: agent-response
data: {"agent":"BrainstormingAgent","preview":"..."}

event: complete
data: {"success":true,"userMessage":{...},"agentMessages":[...]}
```

**Impact**: Users see real-time progress instead of blank screen

---

## Performance Comparison

### Overall Metrics to Watch:

**Response Time** (time from sending message to receiving response):
- Before: 8-20 seconds
- After: 3-8 seconds
- **Improvement**: 60-75% faster

**Database Query Time** (check logs):
- Before: 400-800ms (4 sequential queries)
- After: 100-200ms (1 parallel batch)
- **Improvement**: 75% faster

**Memory Usage** (check with task manager/Activity Monitor):
- Before: ~250MB (backend process)
- After: ~50-80MB (backend process)
- **Improvement**: 68-84% less memory

---

## Test Results Template

Copy this and fill in your results:

```
PHASE 1 TEST RESULTS
Date: ___________
Tester: ___________

‚úÖ Test 1: Singleton Client
   - Appears once in logs: [ ] YES [ ] NO
   - Notes: _______________________________

‚úÖ Test 2: Parallel DB Queries
   - Single log line observed: [ ] YES [ ] NO
   - Approx time saved: _______ ms
   - Notes: _______________________________

‚úÖ Test 3: Parallel Agent Execution
   - Parallel execution observed: [ ] YES [ ] NO
   - Number of agents in parallel: _______
   - Approx time saved: _______ seconds
   - Notes: _______________________________

‚úÖ Test 4: SSE Streaming
   - Streaming endpoint works: [ ] YES [ ] NO [ ] NOT TESTED
   - Events received: _______
   - Notes: _______________________________

OVERALL ASSESSMENT
- Performance improvement: _______% faster
- User experience: [ ] Much Better [ ] Same [ ] Worse
- Issues encountered: _______________________________
- Ready for production: [ ] YES [ ] NO [ ] NEEDS MORE TESTING
```

---

## Quick Verification Commands

### Check if backend is running:
```bash
curl http://localhost:3001/health
```

### Check agent stats:
```bash
curl http://localhost:3001/api/agents/stats
```

### Monitor backend logs in real-time:
Watch the terminal where backend is running for:
- `[Coordination]` - Database query logs
- `[Orchestrator]` - Agent execution logs
- `[BaseAgent]` - Singleton client initialization

---

## Troubleshooting

### If you don't see parallel execution logs:

1. Make sure you're sending the right type of message
2. Check that the workflow has agents marked with `parallel: true`
3. Restart the backend server

### If backend crashes:

1. Check the error logs
2. Verify environment variables in `.env`
3. Check Supabase connection
4. Verify Anthropic API key is valid

### If responses are still slow:

1. Check your internet connection (Claude API calls)
2. Check Supabase latency
3. Verify you're using the updated code

---

## Success Criteria

Phase 1 is successful if:

‚úÖ Backend starts without errors
‚úÖ Singleton client message appears only once
‚úÖ Database queries show as single parallel batch
‚úÖ Agents execute in parallel (visible in logs)
‚úÖ Overall response time is 3-5x faster
‚úÖ No functionality is broken
‚úÖ All existing features work as before

---

## Next Steps After Testing

If all tests pass:
1. ‚úÖ Mark Phase 1 as production-ready
2. üéØ Consider Phase 2 (AI Efficiency) to reduce costs 30-50%
3. üìä Monitor performance in production
4. üêõ Report any issues discovered

If tests fail:
1. Document which test failed
2. Check error logs
3. Verify code changes were applied
4. Ask for help with specific error messages
